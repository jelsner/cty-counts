---
title: "County Counts"
output: html_document
editor_options: 
  chunk_output_type: console
---

Get the SPC dataset. Filter by Year 1950-1989. Create path using buffer. Get county boundaries for Iowa. Aggregate tornado counts by county.

Download the tornado data from the Storm Prediction Center (SPC) http://www.spc.noaa.gov/gis/svrgis/ and load the shapefile into R.
```{r}
library(sf)
download.file(url = "http://www.spc.noaa.gov/gis/svrgis/zipped/1950-2017-torn-aspath.zip",
              destfile = "tornado2017.zip")
unzip("tornado2017.zip")
TornL.sf <- read_sf(dsn = "1950-2017-torn-aspath",
                   stringsAsFactors = FALSE)

download.file(url = "http://www.spc.noaa.gov/gis/svrgis/zipped/1950-2017-torn-initpoint.zip",
              destfile = "tornado2017.zip")
unzip("tornado2017.zip")
TornP.sf <- read_sf(dsn = "1950-2017-torn-initpoint",
                   stringsAsFactors = FALSE)
```

The Paths data set has missing geometries, while the points data set does not.
```{r}
any(is.na(st_dimension(TornL.sf)))
any(is.na(st_dimension(TornP.sf)))
```

Merge the two data sets. Insert point geometries where there are missing linestring geometries.
```{r}
Torn.sf <- TornL.sf
eg <- which(st_is_empty(Torn.sf))
Torn.sf$geometry[eg] <- TornP.sf$geometry[eg]
```

Transform the geographic CRS to a planar projection.
```{r}
library(dplyr)
Torn.sf <- Torn.sf %>%
  st_transform(crs = 3857) %>%
  filter(yr <= 1989) %>%
  filter(mag >= 2 | fat > 0)
```

Get county boundaries for the state of IA.
```{r}
library(USAboundaries)
ctys <- us_counties(states = "IA") %>%
  st_transform(crs = 3857)
```

Start by determining the intersections of the state polygons and the tornado points.

```{r}
mtrx <- st_intersects(ctys, 
                    Torn.sf, 
                    sparse = FALSE)
dim(mtrx)

m <- st_intersects(st_union(ctys),
                 Torn.sf,
                 sparse = FALSE)
sum(m)
```

The result is a 99 (counties) by 8465 (tornadoes) matrix of logical values indicating whether or not each tornado occurred within each state.

Then use the `rowSums()` function to get the total number of TRUE entries for each states.
```{r}
rowSums(mtrx)
```

The order of the elements from the `rowSums()` function matches the order of the states in us_states (alphabetical).

Add these counts as a column in the `ctys` simple feature data frame and compute the annual rate.
```{r}
ctys <- ctys %>%
  mutate(nT = rowSums(mtrx),
         rate = nT/as.numeric(st_area(ctys))/(1989 - 1950 + 1),
         rate = rate * 10^10) %>%
  select(countyfp, name, nT, rate)

ctys %>%
  arrange(desc(nT)) %>%
  as.data.frame %>%
  select(countyfp, name, nT) %>%
  tbl_df %>%
  print(n = 99)

ctys2 <- ctys %>% 
  arrange(name)
```

Make a map.
```{r}
library(tmap)
tm_shape(ctys) +
  tm_borders(col = "gray70") +
  tm_fill("rate",
          title = "Annual Rate\n[/10,000 sq. km]") +
  tm_text("nT") +
  tm_layout(legend.outside = TRUE)

tm_shape(ctys) +
  tm_borders(col = "gray70") +
tm_shape(Torn.sf) +
  tm_lines()
```

Get Grazulis data from Tom Allemeier.
```{r}
library(lubridate)

Graz.df <- read.csv(file = "IowaTornadoes.csv") %>%
  mutate(Date = parse_date_time(Graz.df$date, "mdy")) %>%
  filter(Date >= "1950-01-01")
  
dim(Graz.df)
```

```{r}
library(stringr)
sum(!is.na(str_extract(Graz.df$counties, "ADAIR")))

NAMES <- ctys %>%
  arrange(name) %>%
  pull(name) %>%
  toupper()

head(NAMES)

nTg <- NULL
for(i in 1:length(NAMES)) {
  nTg[i] = sum(!is.na(str_extract(Graz.df$counties, NAMES[i])))
}

ctys2$nTg <- nTg
```

```{r}
ctys2 <- ctys2 %>%
  mutate(rateg = nTg/as.numeric(st_area(ctys2))/(1989 - 1950 + 1),
         rateg = rateg * 10^10)

tm_shape(ctys2) +
  tm_borders(col = "gray70") +
  tm_fill("rateg",
          title = "Annual Rate\n[/10,000 sq. km]") +
  tm_text("nTg") +
  tm_layout(legend.outside = TRUE)
```