---
title: "Compare county-Level tornado counts: SPC vs Grazulis"
output: html_document
editor_options: 
  chunk_output_type: console
---

Get the SPC dataset. Filter by Year 1950-1989. Create tornado damage path using buffer. Get county boundaries for Iowa. Aggregate tornado counts by county.

Download the tornado data from the Storm Prediction Center (SPC) http://www.spc.noaa.gov/gis/svrgis/ and load the shapefile into R.
```{r}
library(sf)
download.file(url = "http://www.spc.noaa.gov/gis/svrgis/zipped/1950-2017-torn-aspath.zip",
              destfile = "tornado2017.zip")
unzip("tornado2017.zip")
TornL.sf <- read_sf(dsn = "1950-2017-torn-aspath",
                   stringsAsFactors = FALSE)

download.file(url = "http://www.spc.noaa.gov/gis/svrgis/zipped/1950-2017-torn-initpoint.zip",
              destfile = "tornado2017.zip")
unzip("tornado2017.zip")
TornP.sf <- read_sf(dsn = "1950-2017-torn-initpoint",
                   stringsAsFactors = FALSE)
```

The Paths data set has missing geometries, while the points data set does not.
```{r}
any(is.na(st_dimension(TornL.sf)))
any(is.na(st_dimension(TornP.sf)))
```

Merge the two data sets. Insert point geometries where there are missing linestring geometries.
```{r}
TornTrack.sf <- TornL.sf
eg <- which(st_is_empty(Torn.sf))
TornTrack.sf$geometry[eg] <- TornP.sf$geometry[eg]
```

Transform the geographic CRS to a planar projection. Remove earlier years. Get only killer tornadoes or those with EF rating 2 or higher. Convert width to meters and buffer the tracks by 1/2 the width.
```{r}
library(dplyr)
TornTrack.sf <- TornTrack.sf %>%
  st_transform(crs = 3857) %>%
  filter(yr >= 1950 & yr <= 1989) %>%
  filter(mag >= 2 | fat > 0) %>%
  mutate(Width = wid * .9144)

TornPath.sf <- st_buffer(TornTrack.sf, 
                         dist = TornTrack.sf$Width/2, 
                         endCapStyle = 'ROUND')
```

Get county boundaries for the state of IA.
```{r}
library(USAboundaries)
ctys <- us_counties(states = "IA") %>%
  st_transform(crs = 3857)  %>%
  rename(GEOID = geoid)
```

Overlay the paths on the counties.
```{r}
library(tmap)
tm_shape(ctys) +
  tm_borders() +
tm_shape(TornPath.sf) +
  tm_polygons(col = "red", border.col = "red") +
tm_shape(ctys) +
    tm_text("name", size = .5, alpha = .4)
```

Count the number of paths intersecting each county.
```{r}
mtrx <- st_intersects(ctys, 
                      TornPath.sf, 
                      sparse = FALSE)
dim(mtrx)

m <- st_intersects(st_union(ctys),
                 Torn.sf,
                 sparse = FALSE)
sum(m)
```

The result is a 99 (counties) by 8465 (tornadoes) matrix of logical values indicating whether or not each tornado occurred within each state.

Then use the `rowSums()` function to get the total number of TRUE entries for each county.
```{r}
rowSums(mtrx)
```

The order of the elements output from the `rowSums()` function matches the order of the counties in `ctys`.

Add these counts as a column in the `ctys` simple feature data frame and compute the annual rate for each county.
```{r}
ctys <- ctys %>%
  mutate(nT = rowSums(mtrx),
         rate = nT/as.numeric(st_area(ctys))/(1989 - 1950 + 1),
         rate = rate * 10^10) %>%
  select(GEOID, name, nT, rate)

ctys %>%
  arrange(desc(nT)) %>%
  as.data.frame %>%
  select(GEOID, name, nT) %>%
  tbl_df %>%
  print(n = 99)
```

Make a choropleth map showing the rate
```{r}
tm_shape(ctys) +
  tm_borders(col = "gray70") +
  tm_fill("rate",
          title = "Annual Rate\n[/10,000 sq. km]") +
  tm_text("nT") +
  tm_layout(legend.outside = TRUE)
```

How well does this map match a map made with the Grazulis data.

Get Grazulis data from Tom Allemeier/Tyler Fricker. Emailed a csv on May 30, 2019.
```{r}
Graz.df <- read.csv(file = "IowaTornadoes.csv") 

library(lubridate)

Graz.df <- Graz.df %>%
  mutate(Date = parse_date_time(date, "mdy")) %>%
  filter(Date >= "1950-01-01" & Date <= "1989-12-31")
  
dim(Graz.df)
```

Use `str_extract()` to get a vector with elements NA and "ADAIR". Adding all non-NA elements gives a count. Repeat for all counties.
```{r}
library(stringr)

str_extract(Graz.df$counties, "ADAIR")
sum(!is.na(str_extract(Graz.df$counties, "ADAIR")))

NAMES <- ctys %>%
  pull(name) %>%
  toupper()

head(NAMES)

nTg <- NULL
for(i in 1:length(NAMES)) {
  nTg[i] = sum(!is.na(str_extract(Graz.df$counties, NAMES[i])))
}

ctys$nTg <- nTg
```

```{r}
ctys <- ctys %>%
  mutate(rateg = nTg/as.numeric(st_area(ctys))/(1989 - 1950 + 1),
         rateg = rateg * 10^10)

tm_shape(ctys) +
#  tm_polygons(c("rate", "rateg"), title = "Annual Rate\n[/10,000 sq. km]") +
  tm_polygons(c("nT", "nTg")) +
  tm_text(c("nT", "nTg")) +
  tm_layout(legend.outside = TRUE)

cor(ctys$nT, ctys$nTg, method = "spearman")
```

```{r}
ctys <- ctys %>%
  mutate(Diff = nT - nTg)

tm_shape(ctys) +
#  tm_borders(col = "gray70") +
  tm_polygons("Diff", n = 5) +
  tm_text("Diff") +
tm_shape(ctys) +
    tm_text("name", size = .5, alpha = .4, ymod = .7)
```

```{r}
ctys %>%
  arrange(desc(Diff))
```

Get population data from the U.S. census.
```{r}
library(tidycensus)
census_api_key("fce1b34522174228a5835e377d3ae0cd80588461", install = TRUE)

IA_pop <- get_acs(geography = "county", 
                     variables = "B01003_001", 
                     state = "IA",
                     geometry = TRUE) %>%
  st_transform(crs = st_crs(ctys))

IA_pop$geometry <- NULL

ctys <- left_join(ctys, IA_pop, by = "GEOID")

cor(ctys$nT, ctys$estimate)
cor(ctys$nTg, ctys$estimate)
```
